{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joejo-joestar/Agentic-AI-Notebooks/blob/main/colab/01_react_agent_demos/02_react_agent_research_papers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3b9adf",
      "metadata": {
        "id": "ef3b9adf"
      },
      "source": [
        "# 02 - ReAct Research Paper Agent Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2727ede7",
      "metadata": {
        "id": "2727ede7"
      },
      "source": [
        "## Requirements\n",
        "These are the required _Libraries_ and _Environment Variables_ for this notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b305d6b",
      "metadata": {
        "id": "0b305d6b"
      },
      "source": [
        "### Libraries Required\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34498210",
      "metadata": {
        "id": "34498210"
      },
      "source": [
        "- [LangSmith](https://docs.langchain.com/langsmith/home)\n",
        "- [LangChain `1.0.3+`](https://reference.langchain.com/python/langchain/langchain/)\n",
        "- [LangChain Core](https://reference.langchain.com/python/langchain_core/)\n",
        "- [LangChain Groq Model Provider](https://reference.langchain.com/python/integrations/langchain_groq/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e56a80",
      "metadata": {
        "collapsed": true,
        "id": "c8e56a80"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --force-reinstall langsmith\n",
        "%pip install --upgrade --force-reinstall langchain\n",
        "%pip install --upgrade --force-reinstall langchain-core\n",
        "\n",
        "%pip install --upgrade --force-reinstall langchain-groq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -iE \"lang(chain|smith)\""
      ],
      "metadata": {
        "id": "QQ3TSijQxXOY",
        "outputId": "6ad458bb-6c5b-41b0-821d-f8f1153fe310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QQ3TSijQxXOY",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain                                1.0.3\n",
            "langchain-core                           1.0.3\n",
            "langchain-groq                           1.0.0\n",
            "langchain-text-splitters                 0.3.11\n",
            "langsmith                                0.4.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff3fdda",
      "metadata": {
        "id": "7ff3fdda"
      },
      "source": [
        "### Variables Required\n",
        "\n",
        "| Token Name             | `.env` Name          | Where to Get / Setting Value                                                      |                                                                                              Reference |\n",
        "| :--------------------- | :------------------- | :-------------------------------------------------------------------------------- | -----------------------------------------------------------------------------------------------------: |\n",
        "| Groq API Key           | `GROQ_API_KEY`       | [Groq Console](https://console.groq.com/keys)                                     |                                              [Groq API Docs](https://console.groq.com/docs/quickstart) |\n",
        "| LangSmith API Key      | `LANGSMITH_API_KEY`  | [LangSmith Settings](https://smith.langchain.com/settings)                        |                                   [LangSmith API Reference](https://docs.langchain.com/langsmith/home) |\n",
        "| LangSmith Tracing      | `LANGSMITH_TRACING`  | A Boolean, set the value to `true` or `false` to enable or disable logging traces | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n",
        "| LangSmith Endpoint     | `LANGSMITH_ENDPOINT` | The LangSmith Endpoint to log the traces (<https://api.smith.langchain.com>)      | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n",
        "| LangSmith Project Name | `LANGSMITH_PROJECT`  | The name of the project to log the traces under                                   | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d825938",
      "metadata": {
        "id": "5d825938"
      },
      "source": [
        "## Actual Shenanigans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c086d0f3",
      "metadata": {
        "id": "c086d0f3"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.tools import tool\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.messages import HumanMessage\n",
        "\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c31da955",
      "metadata": {
        "id": "c31da955"
      },
      "source": [
        "### Defining Tools\n",
        "\n",
        "Read the docs [here](https://reference.langchain.com/python/langchain/tools/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ec094cdd",
      "metadata": {
        "id": "ec094cdd"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def search_arxiv_by_author(author_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for recent papers by a specific author on ArXiv.\n",
        "    This is a mock implementation - in production, integrate with ArXiv API.\n",
        "    \"\"\"\n",
        "    # Mock implementation\n",
        "    papers_db = {\n",
        "        \"Smith\": [\n",
        "            \"Smith et al. (2025) - 'Advances in Climate Modeling' - ArXiv:2501.12345\",\n",
        "            \"Smith, J. (2024) - 'Deep Learning for Environmental Data' - ArXiv:2412.54321\",\n",
        "            \"Smith et al. (2024) - 'Neural Networks for Climate Prediction' - ArXiv:2411.11111\",\n",
        "        ],\n",
        "        \"Johnson\": [\n",
        "            \"Johnson, K. (2025) - 'Machine Learning in Climate Science' - ArXiv:2502.99999\",\n",
        "            \"Johnson et al. (2024) - 'Data Analysis Methods for Climate' - ArXiv:2412.77777\",\n",
        "        ],\n",
        "        \"Brown\": [\n",
        "            \"Brown, L. (2025) - 'Climate Change Mitigation Strategies' - ArXiv:2501.55555\"\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    author = author_name.title()\n",
        "    if author in papers_db:\n",
        "        papers = papers_db[author]\n",
        "        return f\"Found {len(papers)} papers by {author}:\\n\" + \"\\n\".join(\n",
        "            f\"- {p}\" for p in papers\n",
        "        )\n",
        "    else:\n",
        "        return f\"No papers found for author '{author_name}'. Try searching for: Smith, Johnson, or Brown\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_collaborators(author_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Find collaborators of a specific researcher.\n",
        "    \"\"\"\n",
        "    collaborators_db = {\n",
        "        \"Smith\": [\"Johnson\", \"Williams\", \"Chen\"],\n",
        "        \"Johnson\": [\"Smith\", \"Brown\", \"Martinez\"],\n",
        "        \"Brown\": [\"Johnson\", \"Davis\"],\n",
        "        \"Williams\": [\"Smith\", \"Garcia\"],\n",
        "        \"Chen\": [\"Smith\", \"Anderson\"],\n",
        "    }\n",
        "\n",
        "    author = author_name.title()\n",
        "    if author in collaborators_db:\n",
        "        collabs = collaborators_db[author]\n",
        "        return f\"Collaborators of {author}: {', '.join(collabs)}\"\n",
        "    else:\n",
        "        return f\"No collaborator information found for '{author_name}'\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_papers_by_keyword(keyword: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for papers related to a specific keyword in climate science.\n",
        "    \"\"\"\n",
        "    keyword_lower = keyword.lower()\n",
        "    papers_db = {\n",
        "        \"climate change\": [\n",
        "            \"Smith et al. (2025) - 'Advances in Climate Modeling' - ArXiv:2501.12345\",\n",
        "            \"Brown, L. (2025) - 'Climate Change Mitigation Strategies' - ArXiv:2501.55555\",\n",
        "            \"Johnson, K. (2025) - 'Machine Learning in Climate Science' - ArXiv:2502.99999\",\n",
        "        ],\n",
        "        \"neural networks\": [\n",
        "            \"Smith et al. (2024) - 'Neural Networks for Climate Prediction' - ArXiv:2411.11111\",\n",
        "            \"Johnson et al. (2024) - 'Data Analysis Methods for Climate' - ArXiv:2412.77777\",\n",
        "        ],\n",
        "        \"deep learning\": [\n",
        "            \"Smith, J. (2024) - 'Deep Learning for Environmental Data' - ArXiv:2412.54321\"\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for key, papers in papers_db.items():\n",
        "        if keyword_lower in key:\n",
        "            results.extend(papers)\n",
        "\n",
        "    if results:\n",
        "        return f\"Found {len(results)} papers about '{keyword}':\\n\" + \"\\n\".join(\n",
        "            f\"- {p}\" for p in results\n",
        "        )\n",
        "    else:\n",
        "        return f\"No papers found for keyword '{keyword}'. Try: climate change, neural networks, or deep learning\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe9ae8e7",
      "metadata": {
        "id": "fe9ae8e7"
      },
      "source": [
        "### Initializing the Model and the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "af255d7c",
      "metadata": {
        "id": "af255d7c"
      },
      "outputs": [],
      "source": [
        "def create_research_agent():\n",
        "    \"\"\"\n",
        "    Create a ReAct agent that can research papers and collaborators.\n",
        "    \"\"\"\n",
        "    groq_model = ChatGroq(\n",
        "        api_key=userdata.get('GROQ_API_KEY'),\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "\n",
        "    tools = [search_arxiv_by_author, search_collaborators, search_papers_by_keyword]\n",
        "\n",
        "    system_prompt = \"\"\"You are a research assistant specialized in climate science and environmental research.\n",
        "Your task is to help find recent papers and identify collaborators of researchers.\n",
        "\n",
        "When asked about papers by a researcher's collaborators:\n",
        "1. First find who collaborates with that researcher\n",
        "2. Then search for papers by each collaborator\n",
        "3. Compile and present the results clearly\n",
        "\n",
        "Be systematic and thorough in your research.\"\"\"\n",
        "\n",
        "    agent = create_agent(\n",
        "        model=groq_model,\n",
        "        tools=tools,\n",
        "        system_prompt=system_prompt,\n",
        "    )\n",
        "    return agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d4e5e1c2",
      "metadata": {
        "id": "d4e5e1c2"
      },
      "outputs": [],
      "source": [
        "def run_agent_query(agent, query: str):\n",
        "    \"\"\"\n",
        "    Execute a query through the agent and display results.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'=' * 70}\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"{'=' * 70}\\n\")\n",
        "\n",
        "    try:\n",
        "        # Invoke the agent with the user query\n",
        "        result = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
        "\n",
        "        # Extract and display the final response\n",
        "        final_message = result[\"messages\"][-1]\n",
        "        print(\"Agent Response:\")\n",
        "        print(\"-\" * 70)\n",
        "        print(final_message.content)\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing query: {e}\")\n",
        "        import traceback\n",
        "\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cf5e4f",
      "metadata": {
        "id": "38cf5e4f"
      },
      "source": [
        "### Running the Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f885cb",
      "metadata": {
        "id": "f6f885cb"
      },
      "source": [
        "#### Demo the agent with example queries\n",
        "\n",
        "[LangSmith trace](https://smith.langchain.com/public/de99cdc2-e385-476c-b24b-e27180d82b4c/r) for prompt: `Tell me about the researchers collaborating with Johnson on climate research.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c9ecb6e1",
      "metadata": {
        "id": "c9ecb6e1",
        "outputId": "26143212-f030-4720-ef9c-c9aceefc6f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "LangChain ReAct Agent with LangSmith Tracing\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Query: Find recent papers on climate change by Dr. Smith's collaborators.\n",
            "======================================================================\n",
            "\n",
            "Agent Response:\n",
            "----------------------------------------------------------------------\n",
            "Unfortunately, no collaborator information was found for Dr. Smith, and therefore no recent papers on climate change by Dr. Smith's collaborators can be provided. If you have more information about Dr. Smith or their field of research, I may be able to help you find relevant papers or collaborators.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Query: What are the latest papers about neural networks in climate science?\n",
            "======================================================================\n",
            "\n",
            "Agent Response:\n",
            "----------------------------------------------------------------------\n",
            "Here are the latest papers related to neural networks in climate science:\n",
            "\n",
            "1. Smith et al. (2024) - 'Neural Networks for Climate Prediction' - ArXiv:2411.11111\n",
            "2. Johnson et al. (2024) - 'Data Analysis Methods for Climate' - ArXiv:2412.77777\n",
            "3. Smith, J. (2024) - 'Deep Learning for Environmental Data' - ArXiv:2412.54321\n",
            "\n",
            "Additionally, some papers about climate change that might be of interest:\n",
            "\n",
            "1. Smith et al. (2025) - 'Advances in Climate Modeling' - ArXiv:2501.12345\n",
            "2. Brown, L. (2025) - 'Climate Change Mitigation Strategies' - ArXiv:2501.55555\n",
            "3. Johnson, K. (2025) - 'Machine Learning in Climate Science' - ArXiv:2502.99999\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Query: Tell me about the researchers collaborating with Johnson on climate research.\n",
            "======================================================================\n",
            "\n",
            "Error executing query: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=search_collaborators{\"author_name\": \"Johnson\"}</function>'}}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2050667387.py\", line 11, in run_agent_query\n",
            "    result = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\", line 3094, in invoke\n",
            "    for chunk in self.stream(\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\", line 2679, in stream\n",
            "    for _ in runner.tick(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\", line 167, in tick\n",
            "    run_with_retry(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
            "    return task.proc.invoke(task.input, config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\", line 656, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\", line 400, in invoke\n",
            "    ret = self.func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\", line 1065, in model_node\n",
            "    response = _execute_model_sync(request)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\", line 1038, in _execute_model_sync\n",
            "    output = model_.invoke(messages)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\", line 5489, in invoke\n",
            "    return self.bound.invoke(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 382, in invoke\n",
            "    self.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1091, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 906, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1195, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_groq/chat_models.py\", line 544, in _generate\n",
            "    response = self.client.create(messages=message_dicts, **params)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/groq/resources/chat/completions.py\", line 464, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\", line 1242, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/groq/_base_client.py\", line 1044, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "groq.BadRequestError: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=search_collaborators{\"author_name\": \"Johnson\"}</function>'}}\n",
            "During task with name 'model' and id 'd560caf0-1946-561c-3f42-edcab83b054f'\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"LangChain ReAct Agent with LangSmith Tracing\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "agent = create_research_agent()\n",
        "\n",
        "queries = [\n",
        "    \"Find recent papers on climate change by Dr. Smith's collaborators.\",\n",
        "    \"What are the latest papers about neural networks in climate science?\",\n",
        "    \"Tell me about the researchers collaborating with Johnson on climate research.\",\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    run_agent_query(agent, query)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2907f6e",
      "metadata": {
        "id": "f2907f6e"
      },
      "source": [
        "#### Interactive Mode\n",
        "\n",
        "- [LangSmith Trace](https://smith.langchain.com/public/d2bdb8ad-3a97-4207-9afe-a80edfe0f1d6/r) for prompt: `find recent papers on climate change`\n",
        "- [LangSmith Trace](https://smith.langchain.com/public/c3a44a73-80fd-424a-8a65-573587472649/r) for prompt: `what about neural networks?`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f4a8b9",
      "metadata": {
        "id": "e2f4a8b9"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "text = widgets.Text(placeholder=\"Ask away!\")\n",
        "send = widgets.Button(description=\"Send\")\n",
        "out = widgets.Output()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXAMPLE 3: Interactive Mode\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "\n",
        "def on_click(b):\n",
        "    query = text.value.strip()\n",
        "    if not query:\n",
        "        return\n",
        "    text.value = \"\"  # clear input\n",
        "    with out:\n",
        "        try:\n",
        "            run_agent_query(agent, query)\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "\n",
        "send.on_click(on_click)\n",
        "display(widgets.VBox([text, send, out]))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}