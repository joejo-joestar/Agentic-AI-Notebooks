{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5200c8a",
   "metadata": {},
   "source": [
    "# 02 - Agent Routing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d08c6",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "These are the required _Libraries_ and _Environment Variables_ for this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875e052",
   "metadata": {},
   "source": [
    "### Libraries Required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca954bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting up Jupyter widgets and notebook features\n",
    "%conda install conda-forge::ipywidgets --update-deps --force-reinstall\n",
    "%conda install conda-forge::ipykernel --update-deps --force-reinstall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09feed",
   "metadata": {},
   "source": [
    "- [Anthropic](https://docs.claude.com/en/docs/get-started#python)\n",
    "- [nest-asyncio]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install conda-forge::anthropic\n",
    "%conda install conda-forge::nest-asyncio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b994f64",
   "metadata": {},
   "source": [
    "### Variables Required\n",
    "\n",
    "| Token Name        | `.env` Name         | Where to Get / Setting Value                                     |                                                     Reference |\n",
    "| :---------------- | :------------------ | :--------------------------------------------------------------- | ------------------------------------------------------------: |\n",
    "| Anthropic API Key | `ANTHROPIC_API_KEY` | [Anthropic Console](https://console.anthropic.com/settings/keys) | [Anthropic API Docs](https://docs.claude.com/en/api/overview) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path().resolve().parent.parent\n",
    "sys.path.append(str(ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    set_env_variables,\n",
    ")\n",
    "\n",
    "ENV_FILE = ROOT / \".env\"\n",
    "\n",
    "set_env_variables(env_file=ENV_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0827ed8e",
   "metadata": {},
   "source": [
    "## Actual Shenanigans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "from threading import Lock\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "import anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea5f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c2c13",
   "metadata": {},
   "source": [
    "### Initializing Anthropic Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53067210",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()\n",
    "async_client = anthropic.AsyncAnthropic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbbc30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626d69c",
   "metadata": {},
   "source": [
    "### Defining Base Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentType(Enum):\n",
    "    ORDER_STATUS = \"order_status\"\n",
    "    REFUND = \"refund\"\n",
    "    TECHNICAL_SUPPORT = \"technical_support\"\n",
    "    ESCALATION = \"escalation\"\n",
    "\n",
    "\n",
    "class QueryType(Enum):\n",
    "    TRACKING = \"tracking\"\n",
    "    REFUND = \"refund\"\n",
    "    TECHNICAL = \"technical\"\n",
    "    ESCALATION = \"escalation\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Query:\n",
    "    id: int\n",
    "    content: str\n",
    "    query_type: QueryType\n",
    "    priority: int  # 1-5, 5 being highest\n",
    "    timestamp: float\n",
    "    customer_context: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentCapability:\n",
    "    agent_type: AgentType\n",
    "    model_name: str  # Claude model to use\n",
    "    max_tokens: int\n",
    "    temperature: float\n",
    "    system_prompt: str\n",
    "    max_concurrent_tasks: int\n",
    "    capabilities: List[QueryType]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da70ddb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f070f",
   "metadata": {},
   "source": [
    "### Claud Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaudeAgent:\n",
    "    \"\"\"Agent powered by actual Claude API\"\"\"\n",
    "\n",
    "    def __init__(self, agent_id: int, capability: AgentCapability, async_client):\n",
    "        self.agent_id = agent_id\n",
    "        self.capability = capability\n",
    "        self.async_client = async_client\n",
    "        self.current_tasks = 0\n",
    "        self.completed_tasks = 0\n",
    "        self.failed_tasks = 0\n",
    "        self.total_processing_time = 0.0\n",
    "        self.lock = Lock()\n",
    "\n",
    "    def is_available(self) -> bool:\n",
    "        with self.lock:\n",
    "            return self.current_tasks < self.capability.max_concurrent_tasks\n",
    "\n",
    "    def can_handle(self, query: Query) -> bool:\n",
    "        return query.query_type in self.capability.capabilities\n",
    "\n",
    "    async def process_query(self, query: Query) -> dict:\n",
    "        \"\"\"Process query using Claude API\"\"\"\n",
    "        with self.lock:\n",
    "            self.current_tasks += 1\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # Construct messages for Claude\n",
    "            user_message = f\"\"\"Customer Query: {query.content}\n",
    "\n",
    "Query Type: {query.query_type.value}\n",
    "Priority: {query.priority}/5\n",
    "{f\"Context: {query.customer_context}\" if query.customer_context else \"\"}\n",
    "\n",
    "Please provide a helpful, professional response to this customer query.\"\"\"\n",
    "\n",
    "            # Make async API call to Claude\n",
    "            message = await self.async_client.messages.create(\n",
    "                model=self.capability.model_name,\n",
    "                max_tokens=self.capability.max_tokens,\n",
    "                temperature=self.capability.temperature,\n",
    "                system=self.capability.system_prompt,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "            )\n",
    "\n",
    "            # Extract response\n",
    "            response_text = message.content[0].text\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            with self.lock:\n",
    "                self.current_tasks -= 1\n",
    "                self.completed_tasks += 1\n",
    "                self.total_processing_time += processing_time\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"response\": response_text,\n",
    "                \"processing_time\": processing_time,\n",
    "                \"model\": self.capability.model_name,\n",
    "                \"tokens_used\": message.usage.input_tokens + message.usage.output_tokens,\n",
    "            }\n",
    "\n",
    "        except anthropic.RateLimitError as _e:\n",
    "            # Handle rate limiting\n",
    "            with self.lock:\n",
    "                self.current_tasks -= 1\n",
    "                self.failed_tasks += 1\n",
    "\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"rate_limit\",\n",
    "                \"message\": \"API rate limit exceeded\",\n",
    "                \"processing_time\": time.time() - start_time,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            with self.lock:\n",
    "                self.current_tasks -= 1\n",
    "                self.failed_tasks += 1\n",
    "\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(type(e).__name__),\n",
    "                \"message\": str(e),\n",
    "                \"processing_time\": time.time() - start_time,\n",
    "            }\n",
    "\n",
    "    def get_stats(self) -> dict:\n",
    "        with self.lock:\n",
    "            total = self.completed_tasks + self.failed_tasks\n",
    "            return {\n",
    "                \"agent_id\": self.agent_id,\n",
    "                \"type\": self.capability.agent_type.value,\n",
    "                \"model\": self.capability.model_name,\n",
    "                \"completed\": self.completed_tasks,\n",
    "                \"failed\": self.failed_tasks,\n",
    "                \"success_rate\": self.completed_tasks / total if total > 0 else 0,\n",
    "                \"avg_processing_time\": self.total_processing_time / total\n",
    "                if total > 0\n",
    "                else 0,\n",
    "                \"current_load\": self.current_tasks,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b9c3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e2280",
   "metadata": {},
   "source": [
    "### Agent Factory Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_claude_agent_pool(async_client) -> List[ClaudeAgent]:\n",
    "    \"\"\"Create pool of Claude-powered agents with different specializations\"\"\"\n",
    "    agents = []\n",
    "\n",
    "    # Order Status Agents - Fast responses with Claude 3.5 Haiku\n",
    "    for i in range(2):\n",
    "        agents.append(\n",
    "            ClaudeAgent(\n",
    "                agent_id=i,\n",
    "                capability=AgentCapability(\n",
    "                    agent_type=AgentType.ORDER_STATUS,\n",
    "                    model_name=\"claude-3-5-haiku-20241022\",  # Fast & cost-effective\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.3,\n",
    "                    system_prompt=\"\"\"You are an Order Status Agent for an e-commerce platform.\n",
    "Your role is to provide quick, accurate information about order tracking and delivery status.\n",
    "Be concise, friendly, and reassuring. Always include estimated delivery dates when applicable.\"\"\",\n",
    "                    max_concurrent_tasks=3,\n",
    "                    capabilities=[QueryType.TRACKING],\n",
    "                ),\n",
    "                async_client=async_client,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Refund Agents - Moderate complexity with Claude 3.5 Sonnet\n",
    "    for i in range(2, 4):\n",
    "        agents.append(\n",
    "            ClaudeAgent(\n",
    "                agent_id=i,\n",
    "                capability=AgentCapability(\n",
    "                    agent_type=AgentType.REFUND,\n",
    "                    model_name=\"claude-3-5-sonnet-20241022\",  # Balanced performance\n",
    "                    max_tokens=500,\n",
    "                    temperature=0.2,\n",
    "                    system_prompt=\"\"\"You are a Refund Processing Agent for an e-commerce platform.\n",
    "Handle refund requests professionally, explain the refund process clearly, and mention approval timelines.\n",
    "Be empathetic but follow policy guidelines. Mention: processing takes 3-5 business days.\"\"\",\n",
    "                    max_concurrent_tasks=2,\n",
    "                    capabilities=[QueryType.REFUND],\n",
    "                ),\n",
    "                async_client=async_client,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Technical Support Agents - Complex issues with Claude 3.5 Sonnet\n",
    "    for i in range(4, 5):\n",
    "        agents.append(\n",
    "            ClaudeAgent(\n",
    "                agent_id=i,\n",
    "                capability=AgentCapability(\n",
    "                    agent_type=AgentType.TECHNICAL_SUPPORT,\n",
    "                    model_name=\"claude-3-5-sonnet-20241022\",\n",
    "                    max_tokens=800,\n",
    "                    temperature=0.1,\n",
    "                    system_prompt=\"\"\"You are a Technical Support Agent for an e-commerce platform.\n",
    "Troubleshoot complex technical issues including app crashes, payment failures, and website errors.\n",
    "Provide step-by-step solutions. Be patient and thorough. Escalate if issue requires developer intervention.\"\"\",\n",
    "                    max_concurrent_tasks=2,\n",
    "                    capabilities=[QueryType.TECHNICAL],\n",
    "                ),\n",
    "                async_client=async_client,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Escalation Agent - Handles complaints with Claude 3.5 Sonnet (best quality)\n",
    "    agents.append(\n",
    "        ClaudeAgent(\n",
    "            agent_id=5,\n",
    "            capability=AgentCapability(\n",
    "                agent_type=AgentType.ESCALATION,\n",
    "                model_name=\"claude-3-5-sonnet-20241022\",\n",
    "                max_tokens=700,\n",
    "                temperature=0.4,\n",
    "                system_prompt=\"\"\"You are an Escalation Agent handling sensitive customer complaints.\n",
    "Be extremely empathetic, acknowledge frustrations, and offer concrete solutions or compensation.\n",
    "You can handle any query type in escalation mode. Prioritize customer satisfaction and retention.\"\"\",\n",
    "                max_concurrent_tasks=2,\n",
    "                capabilities=[\n",
    "                    QueryType.ESCALATION,\n",
    "                    QueryType.REFUND,\n",
    "                    QueryType.TECHNICAL,\n",
    "                    QueryType.TRACKING,\n",
    "                ],\n",
    "            ),\n",
    "            async_client=async_client,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fb4a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596502f",
   "metadata": {},
   "source": [
    "### Routing Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(ABC):\n",
    "    \"\"\"Abstract base class for routing strategies\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def route(self, query: Query, agents: List[ClaudeAgent]) -> Optional[ClaudeAgent]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_name(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "class CapabilityMatchingRouter(Router):\n",
    "    \"\"\"Routes based on agent capabilities and performance\"\"\"\n",
    "\n",
    "    def route(self, query: Query, agents: List[ClaudeAgent]) -> Optional[ClaudeAgent]:\n",
    "        scored_agents = []\n",
    "\n",
    "        for agent in agents:\n",
    "            if not agent.can_handle(query):\n",
    "                continue\n",
    "\n",
    "            # Calculate comprehensive score\n",
    "            availability_score = 1.0 if agent.is_available() else 0.3\n",
    "\n",
    "            stats = agent.get_stats()\n",
    "            success_score = stats[\"success_rate\"] if stats[\"success_rate\"] > 0 else 0.7\n",
    "\n",
    "            # Model speed approximation (Haiku faster than Sonnet)\n",
    "            speed_score = 1.0 if \"haiku\" in agent.capability.model_name.lower() else 0.7\n",
    "\n",
    "            load_score = 1.0 - (\n",
    "                agent.current_tasks / agent.capability.max_concurrent_tasks\n",
    "            )\n",
    "\n",
    "            # Weighted combination\n",
    "            total_score = (\n",
    "                availability_score * 0.4\n",
    "                + success_score * 0.3\n",
    "                + speed_score * 0.2\n",
    "                + load_score * 0.1\n",
    "            )\n",
    "\n",
    "            scored_agents.append((agent, total_score))\n",
    "\n",
    "        if not scored_agents:\n",
    "            # Fallback: try escalation agent\n",
    "            escalation = [\n",
    "                a for a in agents if a.capability.agent_type == AgentType.ESCALATION\n",
    "            ]\n",
    "            return escalation[0] if escalation else None\n",
    "\n",
    "        return max(scored_agents, key=lambda x: x[1])[0]\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return \"Capability-Matching (Claude-Powered)\"\n",
    "\n",
    "\n",
    "class PriorityRouter(Router):\n",
    "    \"\"\"Priority-based routing with smart fallbacks\"\"\"\n",
    "\n",
    "    def route(self, query: Query, agents: List[ClaudeAgent]) -> Optional[ClaudeAgent]:\n",
    "        # High priority queries go to best available agent\n",
    "        if query.priority >= 4:\n",
    "            capable = [a for a in agents if a.can_handle(query)]\n",
    "            if capable:\n",
    "                # Prefer available agents, then least loaded\n",
    "                available = [a for a in capable if a.is_available()]\n",
    "                pool = available if available else capable\n",
    "                return min(pool, key=lambda a: a.current_tasks)\n",
    "\n",
    "        # Normal priority - standard matching\n",
    "        capable = [a for a in agents if a.can_handle(query) and a.is_available()]\n",
    "\n",
    "        if not capable:\n",
    "            # All busy - find escalation\n",
    "            escalation = [\n",
    "                a for a in agents if a.capability.agent_type == AgentType.ESCALATION\n",
    "            ]\n",
    "            return escalation[0] if escalation else None\n",
    "\n",
    "        return random.choice(capable)\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return \"Priority-Based (Claude-Powered)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ee159",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c52928",
   "metadata": {},
   "source": [
    "### Query Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_realistic_queries(\n",
    "    num_queries: int = 10, load_spike: bool = False\n",
    ") -> List[Query]:\n",
    "    \"\"\"Generate realistic customer service queries\"\"\"\n",
    "    queries = []\n",
    "\n",
    "    # Distribution based on typical e-commerce patterns\n",
    "    if load_spike:\n",
    "        weights = [0.70, 0.20, 0.05, 0.05]  # Black Friday - lots of tracking\n",
    "    else:\n",
    "        weights = [0.50, 0.30, 0.15, 0.05]  # Normal distribution\n",
    "\n",
    "    query_templates = {\n",
    "        QueryType.TRACKING: [\n",
    "            \"Where is my package? Order #12345\",\n",
    "            \"My order hasn't arrived yet. Can you check the status?\",\n",
    "            \"When will my order be delivered? It's been 5 days.\",\n",
    "            \"I need to track my shipment urgently\",\n",
    "        ],\n",
    "        QueryType.REFUND: [\n",
    "            \"I want a refund for my order. The product is defective.\",\n",
    "            \"Can I get my money back? This isn't what I ordered.\",\n",
    "            \"How do I request a refund? Product arrived damaged.\",\n",
    "            \"I'd like to return this item and get a refund\",\n",
    "        ],\n",
    "        QueryType.TECHNICAL: [\n",
    "            \"Your app crashed when I tried to checkout!\",\n",
    "            \"I can't login to my account. Getting error 500.\",\n",
    "            \"The website keeps freezing when I add items to cart.\",\n",
    "            \"Payment not processing - says invalid card but it works elsewhere\",\n",
    "        ],\n",
    "        QueryType.ESCALATION: [\n",
    "            \"This is unacceptable! I've been waiting 3 weeks!\",\n",
    "            \"I want to speak to a manager NOW. This is ridiculous.\",\n",
    "            \"Worst customer service ever. I'm filing a complaint.\",\n",
    "            \"I demand compensation for this terrible experience!\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    contexts = [\n",
    "        \"Customer has ordered 5 times before\",\n",
    "        \"First-time customer\",\n",
    "        \"Premium member since 2023\",\n",
    "        \"Had previous issue resolved successfully\",\n",
    "        None,\n",
    "    ]\n",
    "\n",
    "    query_types = list(QueryType)\n",
    "\n",
    "    for i in range(num_queries):\n",
    "        qtype = random.choices(query_types, weights=weights)[0]\n",
    "        template = random.choice(query_templates[qtype])\n",
    "        priority = 5 if qtype == QueryType.ESCALATION else random.randint(1, 4)\n",
    "\n",
    "        queries.append(\n",
    "            Query(\n",
    "                id=i + 1,\n",
    "                content=template,\n",
    "                query_type=qtype,\n",
    "                priority=priority,\n",
    "                timestamp=time.time(),\n",
    "                customer_context=random.choice(contexts),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35057b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73416992",
   "metadata": {},
   "source": [
    "### Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_claude_simulation(\n",
    "    router: Router,\n",
    "    num_queries: int = 10,\n",
    "    show_responses: bool = True,\n",
    "    rate_limit_delay: float = 0.5,  # Delay between requests to respect rate limits\n",
    "):\n",
    "    \"\"\"Run simulation with actual Claude API calls\"\"\"\n",
    "\n",
    "    print(f\"\\n{'=' * 69}\")\n",
    "    print(f\"RUNNING SIMULATION: {router.get_name()}\")\n",
    "    print(f\"Processing {num_queries} queries with real Claude models\")\n",
    "    print(f\"{'=' * 69}\\n\")\n",
    "\n",
    "    # Initialize\n",
    "    agents = create_claude_agent_pool(async_client)\n",
    "    queries = generate_realistic_queries(num_queries)\n",
    "\n",
    "    # Track metrics\n",
    "    results = []\n",
    "    total_tokens = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Process queries with rate limit consideration\n",
    "    for idx, query in enumerate(queries):\n",
    "        print(\n",
    "            f\"\\n[Query {query.id}/{num_queries}] Type: {query.query_type.value} | Priority: {query.priority}\"\n",
    "        )\n",
    "        print(f\"  Content: {query.content}\")\n",
    "\n",
    "        # Route query\n",
    "        agent = router.route(query, agents)\n",
    "\n",
    "        if agent is None:\n",
    "            print(\"  No agent available\")\n",
    "            results.append({\"success\": False, \"reason\": \"no_agent\"})\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"  Routed to: Agent {agent.agent_id} ({agent.capability.agent_type.value}) using {agent.capability.model_name}\"\n",
    "        )\n",
    "\n",
    "        # Process with Claude\n",
    "        result = await agent.process_query(query)\n",
    "        results.append(result)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            total_tokens += result.get(\"tokens_used\", 0)\n",
    "            print(\n",
    "                f\"  Success | Time: {result['processing_time']:.2f}s | Tokens: {result.get('tokens_used', 0)}\"\n",
    "            )\n",
    "\n",
    "            if show_responses:\n",
    "                response_preview = (\n",
    "                    result[\"response\"][:200] + \"...\"\n",
    "                    if len(result[\"response\"]) > 200\n",
    "                    else result[\"response\"]\n",
    "                )\n",
    "                print(f\"  Response: {response_preview}\\n\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"  ❌ Failed: {result.get('error', 'unknown')} - {result.get('message', '')}\"\n",
    "            )\n",
    "\n",
    "        # Rate limiting: Add delay between requests\n",
    "        if idx < len(queries) - 1:\n",
    "            await asyncio.sleep(rate_limit_delay)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'=' * 69}\")\n",
    "    print(\"SIMULATION SUMMARY\")\n",
    "    print(f\"{'=' * 69}\")\n",
    "\n",
    "    successful = sum(1 for r in results if r.get(\"success\", False))\n",
    "    failed = len(results) - successful\n",
    "\n",
    "    print(f\"Total Queries: {len(results)}\")\n",
    "    print(f\"Successful: {successful} ({successful / len(results) * 100:.1f}%)\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"Total Time: {total_time:.2f}s\")\n",
    "    print(f\"Throughput: {len(results) / total_time:.2f} queries/second\")\n",
    "    print(f\"Total Tokens Used: {total_tokens:,}\")\n",
    "\n",
    "    # Agent performance\n",
    "    print(f\"\\n{'=' * 69}\")\n",
    "    print(\"AGENT PERFORMANCE\")\n",
    "    print(f\"{'=' * 69}\")\n",
    "    print(f\"{'ID':<4} {'Type':<20} {'Model':<30} {'Done':<6} {'Failed':<6} {'Rate':<8}\")\n",
    "    print(\"-\" * 69)\n",
    "\n",
    "    for agent in agents:\n",
    "        stats = agent.get_stats()\n",
    "        print(\n",
    "            f\"{stats['agent_id']:<4} {stats['type']:<20} {stats['model']:<30} \"\n",
    "            f\"{stats['completed']:<6} {stats['failed']:<6} {stats['success_rate']:<8.1%}\"\n",
    "        )\n",
    "\n",
    "    print(f\"{'=' * 69}\\n\")\n",
    "\n",
    "    return results, agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb194d21",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8892f",
   "metadata": {},
   "source": [
    "### Running the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b82cc",
   "metadata": {},
   "source": [
    "#### Demo the agent with example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = CapabilityMatchingRouter()\n",
    "results, agents = await run_claude_simulation(\n",
    "    router=router,\n",
    "    num_queries=5,\n",
    "    show_responses=True,  # Set to False to hide detailed responses\n",
    "    rate_limit_delay=0.5,  # Adjust based on your rate limits\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_edge_case_all_busy():\n",
    "    \"\"\"Test what happens when all specialized agents are busy\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 69)\n",
    "    print(\"EDGE CASE TEST: All Specialized Agents Busy\")\n",
    "    print(\"=\" * 69 + \"\\n\")\n",
    "\n",
    "    agents = create_claude_agent_pool(async_client)\n",
    "    router = CapabilityMatchingRouter()\n",
    "\n",
    "    # Simulate all refund agents being at capacity\n",
    "    for agent in agents:\n",
    "        if agent.capability.agent_type == AgentType.REFUND:\n",
    "            agent.current_tasks = agent.capability.max_concurrent_tasks\n",
    "            print(f\"  Agent {agent.agent_id} (REFUND) set to maximum capacity\")\n",
    "\n",
    "    # Try to route a refund query\n",
    "    test_query = Query(\n",
    "        id=999,\n",
    "        content=\"I need a refund urgently!\",\n",
    "        query_type=QueryType.REFUND,\n",
    "        priority=4,\n",
    "        timestamp=time.time(),\n",
    "    )\n",
    "\n",
    "    routed_agent = router.route(test_query, agents)\n",
    "\n",
    "    if routed_agent:\n",
    "        print(\"\\nFallback Successful!\")\n",
    "        print(f\"   Query routed to: Agent {routed_agent.agent_id}\")\n",
    "        print(f\"   Agent Type: {routed_agent.capability.agent_type.value}\")\n",
    "        print(\n",
    "            f\"   Strategy: {'Escalation Agent' if routed_agent.capability.agent_type == AgentType.ESCALATION else 'Alternative Agent'}\"\n",
    "        )\n",
    "\n",
    "        # Actually process the query\n",
    "        result = await routed_agent.process_query(test_query)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            print(\"\\nResponse Preview:\")\n",
    "            print(f\"   {result['response'][:300]}...\")\n",
    "    else:\n",
    "        print(\"\\n❌ Routing failed - no fallback available\")\n",
    "\n",
    "\n",
    "await test_edge_case_all_busy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a711cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_costs(results: List[dict]):\n",
    "    \"\"\"Estimate API costs based on token usage\"\"\"\n",
    "\n",
    "    # Pricing as of Nov 2025 (check current pricing at https://www.anthropic.com/pricing)\n",
    "    pricing = {\n",
    "        \"claude-3-5-haiku-20241022\": {\n",
    "            \"input\": 0.80 / 1_000_000,  # $0.80 per MTok\n",
    "            \"output\": 4.00 / 1_000_000,  # $4.00 per MTok\n",
    "        },\n",
    "        \"claude-3-5-sonnet-20241022\": {\n",
    "            \"input\": 3.00 / 1_000_000,  # $3.00 per MTok\n",
    "            \"output\": 15.00 / 1_000_000,  # $15.00 per MTok\n",
    "        },\n",
    "    }\n",
    "\n",
    "    total_cost = 0.0\n",
    "    token_breakdown = defaultdict(int)\n",
    "\n",
    "    for result in results:\n",
    "        if result.get(\"success\") and \"tokens_used\" in result:\n",
    "            model = result.get(\"model\", \"claude-3-5-sonnet-20241022\")\n",
    "            tokens = result[\"tokens_used\"]\n",
    "\n",
    "            # Approximate 60% input, 40% output split\n",
    "            input_tokens = int(tokens * 0.6)\n",
    "            output_tokens = int(tokens * 0.4)\n",
    "\n",
    "            if model in pricing:\n",
    "                cost = (\n",
    "                    input_tokens * pricing[model][\"input\"]\n",
    "                    + output_tokens * pricing[model][\"output\"]\n",
    "                )\n",
    "                total_cost += cost\n",
    "                token_breakdown[model] += tokens\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 69)\n",
    "    print(\"COST ESTIMATION\")\n",
    "    print(\"=\" * 69)\n",
    "    print(f\"Total Estimated Cost: ${total_cost:.4f}\")\n",
    "    print(\"\\nToken Usage by Model:\")\n",
    "    for model, tokens in token_breakdown.items():\n",
    "        print(f\"  {model}: {tokens:,} tokens\")\n",
    "    print(\"=\" * 69 + \"\\n\")\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "# Run cost estimation on previous results\n",
    "if \"results\" in locals():\n",
    "    estimate_costs(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dd5c8",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
