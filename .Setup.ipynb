{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a644b9",
   "metadata": {},
   "source": [
    "# Setting Up a Local Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41176ad6",
   "metadata": {},
   "source": [
    "> ℹ️ **Note**\n",
    ">\n",
    "> Make sure the conda environment created from the [readme](README.md) is selected as the kernel for this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad259ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ba554",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea3378",
   "metadata": {},
   "source": [
    "> ℹ️ **Note**\n",
    "> \n",
    "> To install packages from pip in the current conda environment\n",
    ">\n",
    "> Read more info in this over at the [conda documentation](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#using-pip-in-an-environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df074050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting up Jupyter widgets and notebook features\n",
    "%conda install conda-forge::ipywidgets --update-deps --force-reinstall\n",
    "%conda install conda-forge::ipykernel --update-deps --force-reinstall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c645e4d",
   "metadata": {},
   "source": [
    "\n",
    "### Main Dependencies\n",
    "\n",
    "This is a list of dependencies you need for this notebook\n",
    "\n",
    "- [Transformers](https://huggingface.co/docs/transformers/en/index)\n",
    "- [Datasets](https://huggingface.co/docs/datasets/index)\n",
    "- [Tokenizers](https://huggingface.co/docs/tokenizers/index)\n",
    "- [Hugging Face Hub](https://huggingface.co/docs/hub/en/index)\n",
    "- [PyTorch](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install conda-forge::transformers\n",
    "%conda install conda-forge::datasets\n",
    "%conda install conda-forge::tokenizers\n",
    "%conda install conda-forge::huggingface_hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e27895",
   "metadata": {},
   "source": [
    "> ℹ️ **Note**\n",
    ">\n",
    "> Get the latest command from the [get started page](https://pytorch.org/get-started/locally/) (select based on your system configuration)\n",
    ">\n",
    "> The current script installs _**PyTorch with CUDA 12.6**_ Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA 12.6 support\n",
    "%pip install torch --index-url https://download.pytorch.org/whl/cu126\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b589b6",
   "metadata": {},
   "source": [
    "### External APIs and Connectors\n",
    "\n",
    "- [Gemini API](https://ai.google.dev/gemini-api/docs/quickstart)\n",
    "- [OpenAI API](https://platform.openai.com/docs/api-reference/introduction)  \n",
    "- [LangSmith](https://docs.langchain.com/langsmith/home)\n",
    "- LangChain Core\n",
    "- [LangChain Google genai](https://docs.langchain.com/oss/python/integrations/providers/google) package integration (Requires `GOOGLE_API_KEY` to be set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe33e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Model APIs\n",
    "%conda install conda-forge::google-genai\n",
    "%conda install conda-forge::openai\n",
    "%conda install conda-forge::langsmith\n",
    "%conda install conda-forge::langchain-core\n",
    "%conda install conda-forge::langchain\n",
    "\n",
    "# for LangChain Google Gemini Integration\n",
    "%conda install conda-forge::langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1843c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c6839",
   "metadata": {},
   "source": [
    "## Setting Environment Variables\n",
    "\n",
    "A lot of the models and frameworks used in the notebooks in this repo require a Private Access Token or some sort of Secret Keys.\n",
    "To make loading them easier, follow these steps:\n",
    "\n",
    "Before running the following codeblock, create a `.env` file following the [example file](.env.example) provided.\n",
    "\n",
    "The script can be found over in [`utils/env_variables_setup.py`](utils/env_variables_setup.py).\n",
    "\n",
    "More details of this script will can be found in the [readme](README.md)\n",
    "\n",
    "> ℹ️ **Note**\n",
    ">\n",
    "> This script only has to be run once when setting up the environment. Conda environments store the set keys in the environment files (which means they will persist even after restarting the kernel).\n",
    ">\n",
    "> Anytime you update an entry in the `.env` file, you have to run the script to add/update the new/updated variable to the conda environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b780cd97",
   "metadata": {},
   "source": [
    "### Variables Required in This Notebook\n",
    "\n",
    "| Token Name                                                           | `.env` Name         | Where to Get                                                                      |                                                                                                                                                                        Reference |\n",
    "| :------------------------------------------------------------------- | :------------------ | :-------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\n",
    "| Hugging Face User Access Token                                       | `HF_TOKEN`          | [Hugging Face Settings](https://huggingface.co/settings/tokens)                   |                                                                                                                                 [Hugging Face Docs](https://huggingface.co/docs) |\n",
    "| Google Gemini API Key                                                | `GEMINI_API_KEY`    | [Google AI Studio](https://aistudio.google.com/api-keys)                          |                                                                                                              [Gemini API Docs](https://ai.google.dev/gemini-api/docs/quickstart) |\n",
    "| Google Gemini API Key (Used by the `langchain-*` packages)           | `GOOGLE_API_KEY`    | [Google AI Studio](https://aistudio.google.com/api-keys)                          | [Gemini API Docs](https://ai.google.dev/gemini-api/docs/quickstart) and [LangChain Google Integration Docs](https://docs.langchain.com/oss/python/integrations/providers/google) |\n",
    "| OpenAI API Key                                                       | `OPENAI_API_KEY`    | [OpenAI API Platform](https://platform.openai.com/settings/organization/api-keys) |                                                                                              [OpenAI API Reference](https://platform.openai.com/docs/api-reference/introduction) |\n",
    "| LangSmith API Key                                                    | `LANGSMITH_API_KEY` | [LangSmith Settings](https://smith.langchain.com/settings)                        |                                                                                                             [LangSmith API Reference](https://docs.langchain.com/langsmith/home) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "ENV_FILE = ROOT / \".env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146798fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.env_variables_setup import (\n",
    "    set_env_variables,\n",
    ")\n",
    "\n",
    "set_env_variables(env_file=ENV_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unset an environment variable in the conda env.\n",
    "\n",
    "from utils.env_variables_setup import (\n",
    "    unset_env_variable,\n",
    ")\n",
    "\n",
    "unset_env_variable(\"SOME_API_KEY\")  # replace with actual variable name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29486c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all environment variables set in the conda env.\n",
    "\n",
    "from utils.env_variables_setup import (\n",
    "    list_env_variables,\n",
    ")\n",
    "\n",
    "list_env_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77fce9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fe9d7",
   "metadata": {},
   "source": [
    "## Testing the Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac26ef",
   "metadata": {},
   "source": [
    "Some simple code snippets to try out the `transformers` package\n",
    "\n",
    "> 💡**Tip**\n",
    ">\n",
    "> Feel free to go through the [Transformers documentation](https://huggingface.co/docs/transformers/en/index) for the full resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0667ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "prompt = \"Artificial intelligence is transforming the world by\"\n",
    "generated_text = generator(\n",
    "    prompt, max_length=50, truncation=True, num_return_sequences=1\n",
    ")\n",
    "print(generated_text[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aea49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "text = \"AI agents can solve physics problems\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0dedf",
   "metadata": {},
   "source": [
    "Some code snippets to try out the `openai` package\n",
    "\n",
    "> 💡**Tip**\n",
    ">\n",
    "> Feel free to go through the [openai api documentation](https://platform.openai.com/docs/api-reference/introduction) for the full resource\n",
    "\n",
    "> ℹ️ **Note**\n",
    ">\n",
    "> OpenAI requires you to add a minimum credit to use the API service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67360001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# The client gets the API key from the environment variable `OPENAI_API_KEY`.\n",
    "client = OpenAI()\n",
    "\n",
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"o3-mini\", input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    "    )\n",
    "    print(response.output_text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27c3b4",
   "metadata": {},
   "source": [
    "Some code snippets to try out the `google-genai` package\n",
    "\n",
    "> 💡**Tip**\n",
    ">\n",
    "> Feel free to go through the [gemini api documentation](https://ai.google.dev/gemini-api/docs/quickstart) for the full resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f236f",
   "metadata": {},
   "source": [
    "Some code snippets to try out the `langsmith` package\n",
    "\n",
    "> 💡**Tip**\n",
    ">\n",
    "> Feel free to go through the [LangSmith documentation](https://docs.langchain.com/langsmith/home) for the full resource\n",
    "\n",
    "The following scripts are a slightly modified version from the [**Prompt Engineering**](https://docs.langchain.com/langsmith/prompt-engineering-quickstart#sdk) Section of the LangSmith Docs. The change is to use Google's Gemini Model.\n",
    "\n",
    "> ℹ️ **Note**\n",
    ">\n",
    "> The [`@traceable` decorator](https://docs.langchain.com/langsmith/annotate-code) is used to log the traces (you can check your traces in your [LangSmith Dashboard](https://smith.langchain.com/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c437b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_prompt\n",
    "\n",
    "from langsmith import Client\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "client = Client()\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot.\"),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "client.push_prompt(\"prompt-quickstart\", object=prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b65ef3",
   "metadata": {},
   "source": [
    "> ℹ️ **Note**\n",
    ">\n",
    "> This code uses the standalone model package ([`langchain-google-genai`](https://reference.langchain.com/python/integrations/langchain_google_genai/))\n",
    ">\n",
    "> Read the docs for [Provider Specific Integration](https://reference.langchain.com/python/integrations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specific integration\n",
    "\n",
    "from langsmith import Client, traceable\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "@traceable\n",
    "def model_specific_integration():\n",
    "    client = Client()\n",
    "\n",
    "    prompt_obj = client.pull_prompt(\"prompt-quickstart\")\n",
    "    formatted = prompt_obj.invoke({\"question\": \"What is the color of the sky?\"})\n",
    "\n",
    "    # Instantiate Google GenAI model\n",
    "    gemini_2_flash = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    # Invoke the model with the formatted prompt\n",
    "    # The Google GenAI integration expects lists of messages (system/human) as documented:\n",
    "    response = gemini_2_flash.invoke(formatted.messages)\n",
    "\n",
    "    print(response.content)\n",
    "\n",
    "\n",
    "model_specific_integration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475182d7",
   "metadata": {},
   "source": [
    "> ℹ️ **Note**\n",
    ">\n",
    "> This code uses the `langchain` package to create an instance of the gemini model\n",
    ">\n",
    "> Read the docs for the [model initialization](https://reference.langchain.com/python/langchain/models/#chat-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic integration\n",
    "\n",
    "from langsmith import Client, traceable\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "@traceable\n",
    "def generic_integration():\n",
    "    client = Client()\n",
    "\n",
    "    prompt_obj = client.pull_prompt(\"prompt-quickstart\")\n",
    "    formatted = prompt_obj.invoke({\"question\": \"What is the color of the sky?\"})\n",
    "\n",
    "    # Instantiate Google GenAI model\n",
    "    gemini_2_flash = init_chat_model(\"google_genai:gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "    # Invoke the model with the formatted prompt\n",
    "    response = gemini_2_flash.invoke(formatted.messages)\n",
    "\n",
    "    print(response.content)\n",
    "\n",
    "\n",
    "generic_integration()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a543a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crp-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
