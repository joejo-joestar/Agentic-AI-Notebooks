{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3b9adf",
   "metadata": {},
   "source": [
    "# 01 - ReAct Agent Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727ede7",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "These are the required _Libraries_ and _Environment Variables_ for this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b305d6b",
   "metadata": {},
   "source": [
    "### Libraries Required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting up Jupyter widgets and notebook features\n",
    "%conda install conda-forge::ipywidgets --update-deps --force-reinstall\n",
    "%conda install conda-forge::ipykernel --update-deps --force-reinstall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34498210",
   "metadata": {},
   "source": [
    "- [LangSmith](https://docs.langchain.com/langsmith/home)\n",
    "- [LangChain](https://reference.langchain.com/python/langchain/langchain/)\n",
    "- [LangChain Core](https://reference.langchain.com/python/langchain_core/)\n",
    "- [LangChain Groq Model Provider](https://reference.langchain.com/python/integrations/langchain_groq/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e56a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install conda-forge::langsmith\n",
    "%conda install conda-forge::langchain --update-deps --force-reinstall\n",
    "%conda install conda-forge::langchain-core --update-deps --force-reinstall\n",
    "\n",
    "%conda install conda-forge::langchain-groq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3fdda",
   "metadata": {},
   "source": [
    "### Variables Required\n",
    "\n",
    "| Token Name             | `.env` Name          | Where to Get / Setting Value                                                      |                                                                                              Reference |\n",
    "| :--------------------- | :------------------- | :-------------------------------------------------------------------------------- | -----------------------------------------------------------------------------------------------------: |\n",
    "| Groq API Key           | `GROQ_API_KEY`       | [Groq Console](https://console.groq.com/keys)                                     |                                              [Groq API Docs](https://console.groq.com/docs/quickstart) |\n",
    "| LangSmith API Key      | `LANGSMITH_API_KEY`  | [LangSmith Settings](https://smith.langchain.com/settings)                        |                                   [LangSmith API Reference](https://docs.langchain.com/langsmith/home) |\n",
    "| LangSmith Tracing      | `LANGSMITH_TRACING`  | A Boolean, set the value to `true` or `false` to enable or disable logging traces | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n",
    "| LangSmith Endpoint     | `LANGSMITH_ENDPOINT` | The LangSmith Endpoint to log the traces (<https://api.smith.langchain.com>)      | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n",
    "| LangSmith Project Name | `LANGSMITH_PROJECT`  | The name of the project to log the traces under                                   | [LangSmith Observability API Reference](https://docs.langchain.com/langsmith/observability-quickstart) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ab648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set environment variable HF_TOKEN successfully.\n",
      "Set environment variable GOOGLE_API_KEY successfully.\n",
      "Set environment variable OPENAI_API_KEY successfully.\n",
      "Set environment variable GROQ_API_KEY successfully.\n",
      "Set environment variable LANGSMITH_API_KEY successfully.\n",
      "Set environment variable LANGSMITH_TRACING successfully.\n",
      "Set environment variable LANGSMITH_ENDPOINT successfully.\n",
      "Set environment variable LANGSMITH_PROJECT successfully.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from utils.env_variables_setup import (\n",
    "    set_env_variables,\n",
    ")\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "ENV_FILE = ROOT / \".env\"\n",
    "\n",
    "set_env_variables(env_file=ENV_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d825938",
   "metadata": {},
   "source": [
    "## Actual Shenanigans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c086d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.messages import HumanMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31da955",
   "metadata": {},
   "source": [
    "### Defining Tools\n",
    "\n",
    "Read the docs [here](https://reference.langchain.com/python/langchain/tools/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec094cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_arxiv_by_author(author_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for recent papers by a specific author on ArXiv.\n",
    "    This is a mock implementation - in production, integrate with ArXiv API.\n",
    "    \"\"\"\n",
    "    # Mock implementation\n",
    "    papers_db = {\n",
    "        \"Smith\": [\n",
    "            \"Smith et al. (2025) - 'Advances in Climate Modeling' - ArXiv:2501.12345\",\n",
    "            \"Smith, J. (2024) - 'Deep Learning for Environmental Data' - ArXiv:2412.54321\",\n",
    "            \"Smith et al. (2024) - 'Neural Networks for Climate Prediction' - ArXiv:2411.11111\",\n",
    "        ],\n",
    "        \"Johnson\": [\n",
    "            \"Johnson, K. (2025) - 'Machine Learning in Climate Science' - ArXiv:2502.99999\",\n",
    "            \"Johnson et al. (2024) - 'Data Analysis Methods for Climate' - ArXiv:2412.77777\",\n",
    "        ],\n",
    "        \"Brown\": [\n",
    "            \"Brown, L. (2025) - 'Climate Change Mitigation Strategies' - ArXiv:2501.55555\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    author = author_name.title()\n",
    "    if author in papers_db:\n",
    "        papers = papers_db[author]\n",
    "        return f\"Found {len(papers)} papers by {author}:\\n\" + \"\\n\".join(\n",
    "            f\"- {p}\" for p in papers\n",
    "        )\n",
    "    else:\n",
    "        return f\"No papers found for author '{author_name}'. Try searching for: Smith, Johnson, or Brown\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_collaborators(author_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Find collaborators of a specific researcher.\n",
    "    \"\"\"\n",
    "    collaborators_db = {\n",
    "        \"Smith\": [\"Johnson\", \"Williams\", \"Chen\"],\n",
    "        \"Johnson\": [\"Smith\", \"Brown\", \"Martinez\"],\n",
    "        \"Brown\": [\"Johnson\", \"Davis\"],\n",
    "        \"Williams\": [\"Smith\", \"Garcia\"],\n",
    "        \"Chen\": [\"Smith\", \"Anderson\"],\n",
    "    }\n",
    "\n",
    "    author = author_name.title()\n",
    "    if author in collaborators_db:\n",
    "        collabs = collaborators_db[author]\n",
    "        return f\"Collaborators of {author}: {', '.join(collabs)}\"\n",
    "    else:\n",
    "        return f\"No collaborator information found for '{author_name}'\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_papers_by_keyword(keyword: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for papers related to a specific keyword in climate science.\n",
    "    \"\"\"\n",
    "    keyword_lower = keyword.lower()\n",
    "    papers_db = {\n",
    "        \"climate change\": [\n",
    "            \"Smith et al. (2025) - 'Advances in Climate Modeling' - ArXiv:2501.12345\",\n",
    "            \"Brown, L. (2025) - 'Climate Change Mitigation Strategies' - ArXiv:2501.55555\",\n",
    "            \"Johnson, K. (2025) - 'Machine Learning in Climate Science' - ArXiv:2502.99999\",\n",
    "        ],\n",
    "        \"neural networks\": [\n",
    "            \"Smith et al. (2024) - 'Neural Networks for Climate Prediction' - ArXiv:2411.11111\",\n",
    "            \"Johnson et al. (2024) - 'Data Analysis Methods for Climate' - ArXiv:2412.77777\",\n",
    "        ],\n",
    "        \"deep learning\": [\n",
    "            \"Smith, J. (2024) - 'Deep Learning for Environmental Data' - ArXiv:2412.54321\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for key, papers in papers_db.items():\n",
    "        if keyword_lower in key:\n",
    "            results.extend(papers)\n",
    "\n",
    "    if results:\n",
    "        return f\"Found {len(results)} papers about '{keyword}':\\n\" + \"\\n\".join(\n",
    "            f\"- {p}\" for p in results\n",
    "        )\n",
    "    else:\n",
    "        return f\"No papers found for keyword '{keyword}'. Try: climate change, neural networks, or deep learning\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ae8e7",
   "metadata": {},
   "source": [
    "### Initializing the Model and the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af255d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_research_agent():\n",
    "    \"\"\"\n",
    "    Create a ReAct agent that can research papers and collaborators.\n",
    "    \"\"\"\n",
    "    # Initialize the Groq LLM (free tier available)\n",
    "    groq_model = ChatGroq(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "\n",
    "    # Define tools for the agent\n",
    "    tools = [search_arxiv_by_author, search_collaborators, search_papers_by_keyword]\n",
    "\n",
    "    # System prompt to guide the agent's behavior\n",
    "    system_prompt = \"\"\"You are a research assistant specialized in climate science and environmental research.\n",
    "Your task is to help find recent papers and identify collaborators of researchers.\n",
    "\n",
    "When asked about papers by a researcher's collaborators:\n",
    "1. First find who collaborates with that researcher\n",
    "2. Then search for papers by each collaborator\n",
    "3. Compile and present the results clearly\n",
    "\n",
    "Be systematic and thorough in your research.\"\"\"\n",
    "\n",
    "    agent = create_agent(\n",
    "        model=groq_model,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt,\n",
    "    )\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e5e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_query(agent, query: str):\n",
    "    \"\"\"\n",
    "    Execute a query through the agent and display results.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'=' * 70}\\n\")\n",
    "\n",
    "    try:\n",
    "        # Invoke the agent with the user query\n",
    "        result = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "\n",
    "        # Extract and display the final response\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        print(\"Agent Response:\")\n",
    "        print(\"-\" * 70)\n",
    "        print(final_message.content)\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf5e4f",
   "metadata": {},
   "source": [
    "### Running the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f885cb",
   "metadata": {},
   "source": [
    "#### Demo the agent with example queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ecb6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LangChain ReAct Agent with LangSmith Tracing\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Query: Find recent papers on climate change by Dr. Smith's collaborators.\n",
      "======================================================================\n",
      "\n",
      "Agent Response:\n",
      "----------------------------------------------------------------------\n",
      "Based on the search results, Dr. Smith's collaborators could not be found. However, recent papers on climate change include:\n",
      "\n",
      "1. 'Advances in Climate Modeling' by Smith et al. (2025) - ArXiv:2501.12345\n",
      "2. 'Climate Change Mitigation Strategies' by Brown, L. (2025) - ArXiv:2501.55555\n",
      "3. 'Machine Learning in Climate Science' by Johnson, K. (2025) - ArXiv:2502.99999\n",
      "\n",
      "These papers may be of interest to those looking for recent research on climate change.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Query: What are the latest papers about neural networks in climate science?\n",
      "======================================================================\n",
      "\n",
      "Agent Response:\n",
      "----------------------------------------------------------------------\n",
      "It seems the search results did not yield any papers specifically about neural networks in climate science. You may want to try searching for papers on related topics, such as climate change, or machine learning applications in environmental research.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Query: Tell me about the researchers collaborating with Johnson on climate research.\n",
      "======================================================================\n",
      "\n",
      "Error executing query: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=search_arxiv_by_author={\"author_name\": \"Smith\"}</function>\\n'}}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joecn\\AppData\\Local\\Temp\\ipykernel_55288\\2050667387.py\", line 11, in run_agent_query\n",
      "    result = agent.invoke({\"messages\": [HumanMessage(content=query)]})\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 3094, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\pregel\\main.py\", line 2679, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\pregel\\_runner.py\", line 167, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\pregel\\_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 656, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py\", line 400, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain\\agents\\factory.py\", line 1065, in model_node\n",
      "    response = _execute_model_sync(request)\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain\\agents\\factory.py\", line 1038, in _execute_model_sync\n",
      "    output = model_.invoke(messages)\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5489, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ~~~~~~~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "        self._merge_configs(config),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        **{**self.kwargs, **kwargs},\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 379, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1088, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 903, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1192, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\langchain_groq\\chat_models.py\", line 544, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 464, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/openai/v1/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\groq\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\goofy\\Cache\\Conda\\envs\\learning\\Lib\\site-packages\\groq\\_base_client.py\", line 1044, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=search_arxiv_by_author={\"author_name\": \"Smith\"}</function>\\n'}}\n",
      "During task with name 'model' and id 'f4a14963-bc39-e8f4-57d1-d08cddc85019'\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LangChain ReAct Agent with LangSmith Tracing\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "agent = create_research_agent()\n",
    "\n",
    "queries = [\n",
    "    \"Find recent papers on climate change by Dr. Smith's collaborators.\",\n",
    "    \"What are the latest papers about neural networks in climate science?\",\n",
    "    \"Tell me about the researchers collaborating with Johnson on climate research.\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    run_agent_query(agent, query)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2907f6e",
   "metadata": {},
   "source": [
    "#### Interactive Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f4a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXAMPLE 3: Interactive Mode\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5d33ddf6f04edbaa1e1fed1810eb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', placeholder='Ask away!'), Button(description='Send', style=ButtonStyle()), Outpuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "text = widgets.Text(placeholder=\"Ask away!\")\n",
    "send = widgets.Button(description=\"Send\")\n",
    "out = widgets.Output()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE 3: Interactive Mode\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def on_click(b):\n",
    "    query = text.value.strip()\n",
    "    if not query:\n",
    "        return\n",
    "    text.value = \"\"  # clear input\n",
    "    with out:\n",
    "        try:\n",
    "            run_agent_query(agent, query)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "\n",
    "send.on_click(on_click)\n",
    "display(widgets.VBox([text, send, out]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
